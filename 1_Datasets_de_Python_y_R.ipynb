{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# \"DATASETS\" de Python y R en Google Colab\n",
        "\n",
        "Este notebook nos introducirá en la obtención de datos a partir de diversos módulos de Python, destacando la importancia de los datos en la ciencia de datos y la estadística."
      ],
      "metadata": {
        "id": "3qep2KsKPSlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Introducción: La importancia de los datos en la Ciencia de Datos y la Estadística**\n",
        "\n",
        "En la ciencia de datos y la estadística, los datos son el pilar fundamental sobre el cual se construye cualquier análisis o modelo. Sin datos precisos y de calidad, es imposible obtener conclusiones fiables o hacer predicciones útiles. Los datos proporcionan la base para comprender fenómenos, identificar patrones, y tomar decisiones informadas en prácticamente todas las disciplinas.\n",
        "\n",
        "El manejo adecuado de los datos, desde su obtención, limpieza y exploración, es el primer paso en cualquier proyecto de análisis. Conocer las fuentes de datos disponibles y saber cómo acceder a ellas es crucial para un análisis efectivo. En este contexto, aprender a trabajar con datasets utilizando herramientas de programación como Python facilita la implementación de técnicas estadísticas avanzadas y el desarrollo de modelos predictivos.\n",
        "\n",
        "**DATASETS: La base de la Ciencia de Datos**\n",
        "\n",
        "La ciencia de datos y la estadística comienzan con los datos. Antes de aplicar cualquier técnica estadística o modelo, es fundamental obtener, limpiar y entender los datos con los que vamos a trabajar. En este notebook, exploraremos cómo obtener datasets desde diferentes fuentes utilizando módulos de Python.\n"
      ],
      "metadata": {
        "id": "X2ADvJk2PkEe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c12mHWkjP-7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Obtener datos con `vega_datasets`**\n",
        "\n",
        "```python\n",
        "# Importar el módulo vega_datasets\n",
        "from vega_datasets import data\n",
        "\n",
        "# Cargar un dataset de ejemplo\n",
        "cars = data.cars()\n",
        "\n",
        "# Mostrar los primeros registros del dataset\n",
        "cars.head()\n",
        "```\n",
        "\n",
        "Explicación: `vega_datasets` proporciona acceso a una variedad de datasets usados comúnmente para visualización y análisis de datos.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "6J2WhLtxQeUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from vega_datasets import data\n",
        "dir(data)"
      ],
      "metadata": {
        "id": "KEC01DwiQfiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "carros = data.cars()\n",
        "carros.info()"
      ],
      "metadata": {
        "id": "gztrmxRVqj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las primeras filas del DataFrame carros\n",
        "carros.head()"
      ],
      "metadata": {
        "id": "BPgwM-zlr2Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=carros)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "HfJtGHZEsKun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Cargar el archivo de Excel llamado \"/content/drive/MyDrive/2024_SEM_2/1_Estadística_2024_SEM_2/DataFrames/DataFrame carros del módulo vega_datasets.xlsx\"\n",
        "carros_excel = pd.read_excel(\"/content/drive/MyDrive/2024_SEM_2/1_Estadística_2024_SEM_2/DataFrames/DataFrame carros del módulo vega_datasets.xlsx\")\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame cargado\n",
        "carros_excel.head()"
      ],
      "metadata": {
        "id": "bFuZFdwpr_C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio caragr el dataframe \"anscombe\" del modulo vega_datasets\n",
        "from vega_datasets import data\n",
        "anscombe = data.anscombe()\n",
        "anscombe.head(n=3)"
      ],
      "metadata": {
        "id": "ynE2HlSmuoL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las últimas filas de \"anscombe\"\n",
        "anscombe.tail(n=3)"
      ],
      "metadata": {
        "id": "mKfqtoYWvGao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Obtener datos con `seaborn`**\n",
        "\n",
        "```python\n",
        "# Importar el módulo seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "# Cargar el dataset 'iris'\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "# Mostrar los primeros registros del dataset\n",
        "iris.head()\n",
        "```\n",
        "\n",
        "Explicación: `seaborn` es una biblioteca para visualización de datos que también incluye datasets populares como el de `iris`, `tips`, entre otros.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dYKyYVcGQlVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar los datasets del módulo seaborn\n",
        "import seaborn as sns\n",
        "sns.get_dataset_names()"
      ],
      "metadata": {
        "id": "3Ow_5GgPQmen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataframe \"mpg\" del modulo seaborn y mostrar la información del dataframe\n",
        "mpg = sns.load_dataset('mpg')\n",
        "mpg.info()"
      ],
      "metadata": {
        "id": "1xrf5jbvv3m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las 3 primeros filas del dataframe mpg\n",
        "mpg.head(n=3)\n"
      ],
      "metadata": {
        "id": "DQv8yBnKwa69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# @title mpg\n",
        "# import matplotlib.pyplot as plt\n",
        "from matplotlib import pyplot as plt\n",
        "mpg['mpg'].plot(kind='hist', bins=20, title='mpg')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "m7qDygTbzR5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicación del código de la grafica del histograma\n",
        "\n",
        "```python\n",
        "from matplotlib import pyplot as plt\n",
        "mpg['mpg'].plot(kind='hist', bins=20, title='mpg')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Este código utiliza la librería `matplotlib` y el método `plot` de un DataFrame de Pandas para generar un histograma. A continuación te explico en detalle cada línea:\n",
        "\n",
        "### 1. `from matplotlib import pyplot as plt`\n",
        "Esta línea importa el módulo `pyplot` de la biblioteca `matplotlib` y lo nombra como `plt`. `pyplot` es una colección de funciones que permiten crear gráficos de manera similar a la funcionalidad de MATLAB.\n",
        "\n",
        "### 2. `mpg['mpg'].plot(kind='hist', bins=20, title='mpg')`\n",
        "Aquí se está utilizando el método `plot()` del DataFrame `mpg` para crear un gráfico. En este caso, se está generando un **histograma** de la columna `'mpg'` del DataFrame con los siguientes parámetros:\n",
        "- **`kind='hist'`**: Especifica que el tipo de gráfico a crear es un histograma.\n",
        "- **`bins=20`**: Define el número de barras o intervalos (bins) en el histograma. En este caso, el histograma tendrá 20 bins, lo que segmenta los datos en 20 intervalos.\n",
        "- **`title='mpg'`**: Establece el título del gráfico como `'mpg'`.\n",
        "\n",
        "### 3. `plt.gca().spines[['top', 'right',]].set_visible(False)`\n",
        "Esta línea accede al **\"Axis\"** actual (sistema de coordenadas) del gráfico mediante `plt.gca()` (get current axis), y luego modifica la visibilidad de los **bordes** o **spines** del gráfico:\n",
        "- **`spines[['top', 'right']]`**: Selecciona los bordes superior (`top`) y derecho (`right`) del gráfico.\n",
        "- **`set_visible(False)`**: Establece estos bordes como no visibles, lo que significa que se ocultan para hacer el gráfico más limpio y estético.\n",
        "\n",
        "### Resumen del Código\n",
        "Este código genera un **histograma** que representa la distribución de la variable `mpg` (millas por galón) de un DataFrame, dividiéndola en 20 intervalos (bins). Además, se eliminan los bordes superior y derecho del gráfico para mejorar su presentación visual."
      ],
      "metadata": {
        "id": "6ZmCJnem0Gjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las tres ultimas filas\n",
        "mpg.tail(n=3)"
      ],
      "metadata": {
        "id": "mY_8oYy9w0Hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Estadística descriptiva de los dataframes\n",
        "\n",
        "Para generar la estadística descriptiva de un data frame se usa la función describe() de pandas"
      ],
      "metadata": {
        "id": "3f4Kr2LhxBDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar la estadística descriptiva del dataframe mpg\n",
        "mpg.describe()"
      ],
      "metadata": {
        "id": "6dYeDpNfxE3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpretación de la salida de la función describe() de pandas\n",
        "\n",
        "La salida de la función `describe()` de Pandas proporciona estadísticas descriptivas básicas para cada columna del DataFrame `mpg`. Aquí te explico cada una de las métricas mostradas para las columnas:\n",
        "\n",
        "1. **count**: Indica el número de valores no nulos en cada columna.\n",
        "   - Todos los valores de las columnas tienen 398 observaciones, excepto la columna \"horsepower\" que tiene 392 valores, lo que sugiere que hay algunos valores nulos en esa columna.\n",
        "\n",
        "2. **mean**: Es el promedio (media aritmética) de los valores en cada columna.\n",
        "   - Por ejemplo, el consumo promedio (mpg) es 23.51, mientras que el número promedio de cilindros es 5.45.\n",
        "\n",
        "3. **std**: Es la desviación estándar, que mide la dispersión de los valores alrededor de la media.\n",
        "   - Para la columna `mpg`, la desviación estándar es 7.82, lo que indica que los valores de mpg están distribuidos con una variabilidad relativamente amplia en torno a la media.\n",
        "\n",
        "4. **min**: Es el valor mínimo en cada columna.\n",
        "   - El menor valor de `mpg` es 9, mientras que el peso mínimo es 1613.\n",
        "\n",
        "5. **25%**: Este valor representa el primer cuartil o percentil 25. Indica que el 25% de los datos son menores o iguales a este valor.\n",
        "   - Para `mpg`, el 25% de los vehículos tienen un consumo de combustible de 17.5 o menos.\n",
        "\n",
        "6. **50%**: Este es el valor mediano, que divide los datos en dos mitades. El 50% de los datos son menores o iguales a este valor.\n",
        "   - El valor mediano de `mpg` es 23, lo que significa que la mitad de los vehículos tienen un consumo de combustible de 23 mpg o menos.\n",
        "\n",
        "7. **75%**: Es el tercer cuartil o percentil 75. Indica que el 75% de los datos son menores o iguales a este valor.\n",
        "   - Para `mpg`, el 75% de los vehículos tienen un consumo de combustible de 29 mpg o menos.\n",
        "\n",
        "8. **max**: Es el valor máximo en cada columna.\n",
        "   - El consumo de combustible máximo (`mpg`) es 46.6, mientras que el valor máximo para la potencia (`horsepower`) es 230.\n",
        "\n",
        "En resumen, esta salida te da una idea general de la distribución de cada variable. Puedes observar la media, la dispersión, y los rangos en los que caen los valores para características como el consumo de combustible (`mpg`), el número de cilindros, el desplazamiento del motor, la potencia, el peso, la aceleración y el año del modelo."
      ],
      "metadata": {
        "id": "SQaKfrZzyZV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar la documentación del dataframe mpg\n",
        "mpg?"
      ],
      "metadata": {
        "id": "QDcpzbNYw-r2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Obtener datos de R con `statsmodels`**\n",
        "\n",
        "```python\n",
        "# Importar el módulo statsmodels\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Obtener un dataset de R (por ejemplo, 'iris' desde R)\n",
        "iris_r = sm.datasets.get_rdataset('iris')\n",
        "\n",
        "# Convertir el dataset en un DataFrame de pandas\n",
        "iris_r_data = iris_r.data\n",
        "\n",
        "# Mostrar los primeros registros del dataset\n",
        "iris_r_data.head()\n",
        "```\n",
        "\n",
        "Explicación: `statsmodels` permite acceder a datasets de R utilizando la función `get_rdataset`, lo que facilita la importación de datos desde paquetes de R a Python.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HoMTpGcxQru-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataframe Boston del paquete MASS, utilizando el módulo statsmodels\n",
        "import statsmodels.api as sm\n",
        "boston = sm.datasets.get_rdataset('Boston',\"MASS\")\n",
        "boston_data = boston.data\n",
        "boston_data.head()"
      ],
      "metadata": {
        "id": "zNGyZhQhQskU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(boston_data.info()))"
      ],
      "metadata": {
        "id": "uo4zTaSH15v-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataframe Boston del paquete MASS, utilizando el módulo statsmodels\n",
        "import statsmodels.api as sm\n",
        "boston = sm.datasets.get_rdataset('Boston',\"MASS\").data\n",
        "boston.head()\n"
      ],
      "metadata": {
        "id": "1i6X6nUB1sZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Guía: Montar Google Drive y manipular archivos en Colab\n",
        "\n",
        "## 1. Montar Google Drive en Google Colab\n",
        "\n",
        "Primero, necesitamos acceder a los archivos de tu Google Drive desde el notebook de Google Colab. Para hacerlo, ejecutamos el siguiente código:\n",
        "\n",
        "```python\n",
        "# Montar Google Drive en Colab\n",
        "from google.colab import drive\n",
        "\n",
        "# Montar el drive en la carpeta '/content/drive'\n",
        "drive.mount('/content/drive')\n",
        "```\n",
        "\n",
        "Al ejecutar este código, Colab solicitará autenticación para acceder a tu Google Drive. Sigue las instrucciones que aparecen en pantalla y otorga los permisos necesarios.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Navegar por los archivos en Google Drive\n",
        "\n",
        "Después de montar Google Drive, puedes navegar por tus archivos como lo harías en tu computadora. Aquí te muestro cómo listar archivos en una carpeta específica:\n",
        "\n",
        "```python\n",
        "# Importar el módulo os para trabajar con rutas de archivos\n",
        "import os\n",
        "\n",
        "# Especificar la ruta a una carpeta en Google Drive\n",
        "folder_path = '/content/drive/My Drive/NOMBRE_DE_TU_CARPETA'\n",
        "\n",
        "# Listar los archivos en esa carpeta\n",
        "os.listdir(folder_path)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Leer y manipular archivos de Excel\n",
        "\n",
        "Para trabajar con archivos de Excel, usamos el módulo `pandas`. Asegúrate de que el archivo esté en tu Google Drive y luego puedes leerlo como se muestra:\n",
        "\n",
        "```python\n",
        "# Importar pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Especificar la ruta del archivo de Excel\n",
        "excel_file = '/content/drive/My Drive/NOMBRE_DE_TU_CARPETA/archivo.xlsx'\n",
        "\n",
        "# Leer el archivo de Excel\n",
        "df_excel = pd.read_excel(excel_file)\n",
        "\n",
        "# Mostrar las primeras filas del archivo\n",
        "df_excel.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Leer y manipular archivos CSV\n",
        "\n",
        "Los archivos CSV son comunes en el análisis de datos y también se pueden leer fácilmente con `pandas`:\n",
        "\n",
        "```python\n",
        "# Especificar la ruta del archivo CSV\n",
        "csv_file = '/content/drive/My Drive/NOMBRE_DE_TU_CARPETA/archivo.csv'\n",
        "\n",
        "# Leer el archivo CSV\n",
        "df_csv = pd.read_csv(csv_file)\n",
        "\n",
        "# Mostrar las primeras filas del archivo\n",
        "df_csv.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Leer y manipular archivos de texto (TXT)\n",
        "\n",
        "Los archivos de texto también son útiles para almacenar datos, y `pandas` puede leer archivos delimitados por tabulaciones u otros separadores:\n",
        "\n",
        "```python\n",
        "# Especificar la ruta del archivo TXT\n",
        "txt_file = '/content/drive/My Drive/NOMBRE_DE_TU_CARPETA/archivo.txt'\n",
        "\n",
        "# Leer el archivo de texto (suponiendo que esté delimitado por comas)\n",
        "df_txt = pd.read_csv(txt_file, delimiter='\\t')  # Cambia el delimitador si es necesario\n",
        "\n",
        "# Mostrar las primeras filas del archivo\n",
        "df_txt.head()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 6. Guardar archivos manipulados de vuelta en Google Drive\n",
        "\n",
        "Puedes guardar tus archivos de nuevo en Google Drive después de manipularlos:\n",
        "\n",
        "```python\n",
        "# Especificar la ruta para guardar el archivo CSV manipulado\n",
        "output_csv = '/content/drive/My Drive/NOMBRE_DE_TU_CARPETA/archivo_modificado.csv'\n",
        "\n",
        "# Guardar el DataFrame como un nuevo archivo CSV\n",
        "df_csv.to_csv(output_csv, index=False)\n",
        "\n",
        "# Especificar la ruta para guardar el archivo Excel manipulado\n",
        "output_excel = '/content/drive/My Drive/NOMBRE_DE_TU_CARPETA/archivo_modificado.xlsx'\n",
        "\n",
        "# Guardar el DataFrame como un archivo Excel\n",
        "df_excel.to_excel(output_excel, index=False)\n",
        "```"
      ],
      "metadata": {
        "id": "WmnDdzQgSj7L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOz52wQTS6cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Obtener datos desde archivos de Excel con `pandas`**\n",
        "\n",
        "1. Carque Google Drive\n",
        "2. Monte los archivos de Excel, csv y demás\n",
        "3. Use pandas para cargar los distintos datasets\n",
        "\n",
        "```python\n",
        "# Importar pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Leer un archivo de Excel con varias hojas (suponiendo que el archivo está en la misma carpeta)\n",
        "# El archivo 'data.xlsx' tiene varias hojas, por ejemplo, 'Hoja1', 'Hoja2'\n",
        "excel_file = 'data.xlsx'\n",
        "\n",
        "# Cargar todas las hojas en un diccionario de DataFrames\n",
        "all_sheets = pd.read_excel(excel_file, sheet_name=None)\n",
        "\n",
        "# Mostrar las claves del diccionario (nombres de las hojas)\n",
        "all_sheets.keys()\n",
        "\n",
        "# Acceder a una de las hojas (por ejemplo, 'Hoja1')\n",
        "hoja1 = all_sheets['Hoja1']\n",
        "\n",
        "# Mostrar los primeros registros de la hoja1\n",
        "hoja1.head()\n",
        "```\n",
        "\n",
        "Explicación: `pandas` permite la lectura de archivos de Excel con múltiples hojas mediante `read_excel` con el parámetro `sheet_name=None`.\n",
        "\n",
        "---\n",
        "\n",
        "## Conclusión\n",
        "\n",
        "En este notebook hemos explorado diversas formas de obtener datos utilizando Python. Ya sea desde librerías especializadas, como `vega_datasets` y `seaborn`, desde paquetes de R con `statsmodels`, o desde archivos de Excel con `pandas`, contar con los datos correctos es el primer paso para cualquier análisis estadístico o científico de datos.\n",
        "```"
      ],
      "metadata": {
        "id": "CkcUzUODO88N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "oQp60GF923gi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cargar un archivo csv de nombre:\n",
        "\n",
        "\"/content/drive/MyDrive/2024_SEM_2/1_Estadística_2024_SEM_2/Tema 2 Datasets: vega_datasets en Python y Paquetes de R/housing.csv\""
      ],
      "metadata": {
        "id": "vWOqpKlZ3Yuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el archivo csv llamado \"/content/drive/MyDrive/2024_SEM_2/1_Estadística_2024_SEM_2/Tema 2 Datasets: vega_datasets en Python y Paquetes de R/housing.csv\"\n",
        "import pandas as pd\n",
        "housing = pd.read_csv(\"/content/drive/MyDrive/2024_SEM_2/1_Estadística_2024_SEM_2/Tema 2 Datasets: vega_datasets en Python y Paquetes de R/housing.csv\")\n",
        "housing.head()"
      ],
      "metadata": {
        "id": "vzuXtlXE3fSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "housing.info()"
      ],
      "metadata": {
        "id": "Z6kYZHGa4NZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar las columnas del dataframe housing\n",
        "housing.columns"
      ],
      "metadata": {
        "id": "4ICKgPLe3wy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar las columnas 'longitude', 'latitude'\n",
        "housing.plot.scatter(x='longitude', y='latitude')"
      ],
      "metadata": {
        "id": "NL-x9YIN3-Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAQxzux6O8PY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. streamlit**\n",
        "\n",
        "Streamlit es un marco de trabajo Python de código abierto para científicos de datos e ingenieros de IA/ML que les permite crear aplicaciones de datos dinámicas con solo unas pocas líneas de código. Cree e implemente aplicaciones de datos potentes en minutos. ¡Comencemos!\n",
        "\n",
        "[Documentación de Streamlit](https://docs.streamlit.io/)\n",
        "\n",
        "1. Instale Python\n",
        "2. Instale Microsoft VsCode\n",
        "3. Cree un ambiente de trabajo (Entorno Virtual) en un proyecto\n",
        "4. Instale streamlit\n",
        "5. Comience lanzando la orden:\n",
        "```\n",
        "streamlit hello\n",
        "```\n",
        "6. Inscribase y cree scripts de Python, por ejemplo: **app.py**\n",
        "8. Implemente lanzando la orden:\n",
        "```\n",
        "streamlit run app.py\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P_BrQHRpfHD6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azH1VF9kfjax"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}